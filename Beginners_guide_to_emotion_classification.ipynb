{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEa6B6q+nV2UTy+nMbzwWH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Dimi-G/Capstone_Project/blob/main/Beginners_guide_to_emotion_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Project description\n",
        "As part of our personalized diary assistant (link to follow soon), we need to be able to identify emotions from text entries. The approach is that of an NLP-based multiclass classification task. Our training dataset is [dar-ai/emotion](https://huggingface.co/datasets/dair-ai/emotion). We introduce a K-Nearest Neighbors naive model and proceed with implementing transfer learning from the [RoBERTa](https://huggingface.co/docs/transformers/v4.41.3/en/model_doc/roberta#transformers.RobertaForSequenceClassification) model.\n",
        "\n",
        "Special thanks to [bhadresh-savani](https://huggingface.co/bhadresh-savani/roberta-base-emotion), whose notebook was the main guide for this work but also to many others who have shared their work and contributed to better understanding this fascinating topic."
      ],
      "metadata": {
        "id": "A0lqF9rOVpT8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "rIIBpumPZGFn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H8hxGEgWAnwm"
      },
      "outputs": [],
      "source": [
        "#setting the gpu as first choice if it is accessible\n",
        "import torch\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#mounting google drive for saving or loading the models\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KKQ_rUnJa_u6",
        "outputId": "2588fb31-d5e3-4c82-bd8f-6bd2c0caef55"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#huggingface and pytorch relevant installations\n",
        "! pip install -U sentence-transformers\n",
        "! pip install -q datasets\n",
        "! pip install -U accelerate\n",
        "! pip install -U transformers\n"
      ],
      "metadata": {
        "id": "Gl3GWQnAaIuf",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#installing joblib for saving the KNN model\n",
        "!pip install joblib"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peK6EjYvZtn8",
        "outputId": "e8701af8-ac2b-46ad-8882-ac49e2bd4cda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (1.4.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import joblib\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import RandomizedSearchCV, cross_val_score\n",
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import RobertaTokenizer, RobertaForSequenceClassification\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n"
      ],
      "metadata": {
        "id": "WNWf3PyYZ6_T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Naive Model"
      ],
      "metadata": {
        "id": "velX2zBBd9x7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset import from Kaggle\n",
        "\n",
        "The same emotions for NLP dataset is available in [Kaggle](https://www.kaggle.com/datasets/praveengovi/emotions-dataset-for-nlp). It can be downloaded and added to google drive to be accessed locally."
      ],
      "metadata": {
        "id": "4Y-xMQDleFcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.read_csv(\"drive/MyDrive/NLP_data/train.txt\", delimiter=\";\", names=[\"text\", \"label\"])\n",
        "val_df = pd.read_csv(\"drive/MyDrive/NLP_data/val.txt\", delimiter=\";\", names=[\"text\", \"label\"])\n",
        "test_df = pd.read_csv(\"drive/MyDrive/NLP_data/test.txt\", delimiter=\";\", names=[\"text\", \"label\"])"
      ],
      "metadata": {
        "id": "THJImCJcPrd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# splitting datasets in half to reduce size\n",
        "RANDOM_SEED =42\n",
        "train_ds = train_df.sample(frac=0.5, random_state= RANDOM_SEED)\n",
        "val_ds = val_df.sample(frac=0.5, random_state= RANDOM_SEED)\n",
        "test_ds = test_df.sample(frac=0.5, random_state= RANDOM_SEED)"
      ],
      "metadata": {
        "id": "6Ab9kEIvQJ9G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Basic Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "gh7ifQGsQ836"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking the distribution of the labels"
      ],
      "metadata": {
        "id": "TRHW4dkQQYic"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds['label'].value_counts()/train_ds.shape[0]"
      ],
      "metadata": {
        "id": "0pfte5sQQXnp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Training dataset: \\n shape: {train_ds.shape} \\n label counts:{train_ds['label'].value_counts()} \\n label ratios: {train_ds['label'].value_counts()/train_ds.shape[0]}\")\n",
        "print(f\"Training dataset: \\n shape: {test_ds.shape} \\n label counts:{test_ds['label'].value_counts()} \\n label ratios: {test_ds['label'].value_counts()/test_ds.shape[0]}\")\n",
        "print(f\"Training dataset: \\n shape: {val_ds.shape} \\n label counts:{val_ds['label'].value_counts()} \\n label ratios: {val_ds['label'].value_counts()/val_ds.shape[0]}\")"
      ],
      "metadata": {
        "id": "MY5tMe7UQcR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset is split. Data is imbalanced but we have the same ratios per split."
      ],
      "metadata": {
        "id": "lYU8iPu6QrJy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.groupby('label').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "metadata": {
        "id": "ymlUPq1kQ7R3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Creating embeddings\n",
        "\n",
        "Text embeddings are vectors (lists) or floating point numbers and they are designed to capture the semantic meaning and context of the words they represent. There are many models available which can be used for getting embeddings from given text. In this case we will use directly a [RoBERTa embedding Transformer](https://huggingface.co/sentence-transformers/all-roberta-large-v1). A more traditional approach would be employing CountVectorizer, TF-IDF, N-grams, Normalization, Stemming, Lemmatization, Stopwords, POS-tagging etc."
      ],
      "metadata": {
        "id": "Uk_7jR3AeWql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "embedder = SentenceTransformer('sentence-transformers/all-roberta-large-v1')"
      ],
      "metadata": {
        "id": "gJ-wXagtSfSc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Input format has to be a list"
      ],
      "metadata": {
        "id": "9E-xh74pSljs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_sentences = train_ds['text'].to_list()\n",
        "test_sentences = test_ds['text'].to_list()\n",
        "val_sentences = val_ds['text'].to_list()"
      ],
      "metadata": {
        "id": "-IQd0lyHSk89"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings = embedder.encode(train_sentences)\n",
        "test_embeddings = embedder.encode(test_sentences)\n",
        "val_embeddings = embedder.encode(val_sentences)"
      ],
      "metadata": {
        "id": "Fb7OrVrdSpVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_embeddings.shape"
      ],
      "metadata": {
        "id": "dTUPFnUeStvT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training dataset embeddings have 8000 data points, each represented by a 1024-dimensional vector"
      ],
      "metadata": {
        "id": "14NjX_eoTb2T"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN model and Hyperparameter tuning\n",
        "\n",
        "Initialize KNeighborsClassifier and fit on training data"
      ],
      "metadata": {
        "id": "lGRrLDNdecAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_baseline = KNeighborsClassifier()\n",
        "model_baseline.fit(train_embeddings, train_ds['label'])"
      ],
      "metadata": {
        "id": "XK_FfjPUUOc7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scoring metric of choice is the F1-score, which is a harmonic mean of precision and recall. The F1-score is more sensitive to data distribution and is a suitable measure for classification problems on imbalanced datasets.\n"
      ],
      "metadata": {
        "id": "IY3RJt2gUqor"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cv_scores = cross_val_score(estimator=model_baseline, X=train_embeddings, y=train_ds['label'], scoring=\"f1_macro\", cv=3)\n",
        "\n",
        "print(\n",
        "    f\"\"\"\n",
        "      Baseline model CV scores by fold: {cv_scores},\n",
        "      Mean CV score {cv_scores.mean()}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "VVflbfURUVV4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running a Randomized Search CV on a set of hyperparameters for the KNN"
      ],
      "metadata": {
        "id": "uVei3yecVO9G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "params = {\n",
        "    \"n_neighbors\": [3, 5, 7, 9, 11, 13, 15], # number of neighbors\n",
        "    \"weights\": [\"distance\", \"uniform\"], # whether the votes from all neighbors should be counted equally or by distance to the prediction point\n",
        "    \"metric\": [\"cosine\", \"euclidean\" ], # which metric to use for distance calculation\n",
        "}\n",
        "\n",
        "# define RandomizedSearchCV\n",
        "clf = RandomizedSearchCV(\n",
        "    estimator=KNeighborsClassifier(n_jobs=-1),\n",
        "    param_distributions=params,\n",
        "    n_iter=20,\n",
        "    random_state=0,\n",
        "    cv=3,\n",
        "    scoring=\"f1_macro\",\n",
        ")"
      ],
      "metadata": {
        "id": "MqCifwAeU7xY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "random_search = clf.fit(train_embeddings, train_ds['label'])"
      ],
      "metadata": {
        "id": "f4FRl71hVA3m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\"\"\n",
        "      Best parameters: {random_search.best_params_}\n",
        "      F1-score: {random_search.best_score_}\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "kCefv0AoVEbc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Calling in the model with the best hyperparameters"
      ],
      "metadata": {
        "id": "psWP8r5FWBdq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_knn_model = random_search.best_estimator_\n",
        "cv_scores_tuned = cross_val_score(estimator=best_knn_model, X=train_embeddings, y=train_ds['label'], scoring=\"f1_macro\", cv=3)\n",
        "\n",
        "print(\n",
        "    f\"\"\"\n",
        "      Best model CV scores by fold: {cv_scores_tuned},\n",
        "      Mean CV scores: {cv_scores_tuned.mean()}\n",
        "\"\"\"\n",
        ")"
      ],
      "metadata": {
        "id": "6rg66uhXWJWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "KNN with Hyperparameter tuning return marginally improved F1 score. We use the best estimator for prediction and print a classification report"
      ],
      "metadata": {
        "id": "rTE9d6qpWgnC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Evaluation"
      ],
      "metadata": {
        "id": "O7F5Lw9WemqW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = best_knn_model.predict(test_embeddings)"
      ],
      "metadata": {
        "id": "RIqNLZLyWrqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting y test to 1d array to match the y_pred for the classification report input\n",
        "y_test = test_ds['label'].values"
      ],
      "metadata": {
        "id": "FLp9DnvgW2v9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, y_pred ))"
      ],
      "metadata": {
        "id": "oS8M-t6oW57e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Saving KNN model"
      ],
      "metadata": {
        "id": "YRH_BGwiegqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#saving the KNN best model\n",
        "joblib_file = \"knn_model.joblib\"\n",
        "joblib.dump(best_knn_model, joblib_file)\n",
        "\n",
        "# Copy the model file to Google Drive\n",
        "!cp knn_model.joblib /content/drive/MyDrive/NLP_data/knn_model.joblib"
      ],
      "metadata": {
        "id": "PLRWuFA3XYON"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Zero-shot classification\n",
        "\n",
        "We test Zero-shot classification performance on our labels using the [facebook/bart-large-mnli](https://huggingface.co/facebook/bart-large-mnli) pipeline. It allows for text categorization without specific training on your labels. This pipeline takes your text and potential labels as input, predicting which labels apply based on the model's pre-existing knowledge. The results of the pipeline are for multilabel classification.\n"
      ],
      "metadata": {
        "id": "we_HLtVVeKn-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_shot_classifier = pipeline(\"zero-shot-classification\",\n",
        "                      model=\"facebook/bart-large-mnli\")"
      ],
      "metadata": {
        "id": "tnc9plHtZsuF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Bringing data in the necessary format for the pipeline and saving in a list only the prevailing category prediction"
      ],
      "metadata": {
        "id": "iVRJzm1oZxPT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "candidate_labels = list(train_ds['label'].unique())"
      ],
      "metadata": {
        "id": "i3U5aAOjZ1nh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = test_ds['text'].to_list()"
      ],
      "metadata": {
        "id": "SgLAqaaVZ5aX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "prediction = zero_shot_classifier(sequences, candidate_labels)"
      ],
      "metadata": {
        "id": "NXc9EUzHZ86H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Choosing the label with the highest prediction score\n",
        "pred_list = [prediction[i]['labels'][0] for i in range(0,len(prediction))]"
      ],
      "metadata": {
        "id": "VYpXfybKaHry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(pred_list)"
      ],
      "metadata": {
        "id": "ZyALcmipaVme"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Performance Evaluation"
      ],
      "metadata": {
        "id": "ya8Sgf8xepl1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_test, pred_list ))"
      ],
      "metadata": {
        "id": "22hRsZcnaZjJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Bart zero shot classification does not perform better than the baseline KNN model. Especially the performance of the 'surprise' category is so poor that drops the macro accuracy."
      ],
      "metadata": {
        "id": "8MrcwmxFacho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## RoBERTa: A Robustly Optimized BERT Pretraining Approach"
      ],
      "metadata": {
        "id": "REn3xKe3es4j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import dataset from Hugging Face\n",
        "Using the same [emotion dataset](https://huggingface.co/datasets/dair-ai/emotion) but this time from the Hugginng Face interface.\n",
        "Labels are sadness (0), joy (1), love (2), anger (3), fear (4), surprise (5)."
      ],
      "metadata": {
        "id": "KS_dLlXOe41h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "emotions = load_dataset(\"emotion\")"
      ],
      "metadata": {
        "id": "M_z1JOVUdNND"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Checking dataset format, tokenizing, downsizing"
      ],
      "metadata": {
        "id": "en7Q9AbeeN_B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions"
      ],
      "metadata": {
        "id": "aZenLXz4eZaC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = RobertaTokenizer.from_pretrained(\"FacebookAI/roberta-base\")"
      ],
      "metadata": {
        "id": "NaoQwnfZfZMG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize function\n",
        "def tokenize(batch):\n",
        "  return tokenizer(batch['text'], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "5IGE5H02eanK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched =True, batch_size =None)"
      ],
      "metadata": {
        "id": "nTWbSAWAej2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#making a smaller dataset. since for the baseline models we used 50% of each split, we will use the same size and random seed too\n",
        "RANDOM_SEED = 42\n",
        "small_train_ds = emotions_encoded['train'].shuffle(seed=RANDOM_SEED).select(range(8000))\n",
        "small_val_ds =  emotions_encoded['validation'].shuffle(seed=RANDOM_SEED).select(range(1000))\n",
        "small_test_ds = emotions_encoded['test'].shuffle(seed=RANDOM_SEED).select(range(1000))"
      ],
      "metadata": {
        "id": "SEwnjR08enSd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prepare the datasets for use with PyTorch models"
      ],
      "metadata": {
        "id": "LDgKTmnff7OC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "small_train_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "small_val_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "small_test_ds.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])"
      ],
      "metadata": {
        "id": "pHjUrxJme6-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Metrics"
      ],
      "metadata": {
        "id": "vOfLxYj4gFLP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "MwDDwltXgjIr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train a RoBERTa custom classification head"
      ],
      "metadata": {
        "id": "_cxPzk8LgAO6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use the RobertaForSequenceClassification class, which is a transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output).  The last step utilizes a softmax activation function for multiclass classification. The default optimizer is AdamW, while the cost function is Categorical Cross-Entropy (Softmax activation plus a Cross-Entropy loss)"
      ],
      "metadata": {
        "id": "gL0WY8XVhYSr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"FacebookAI/roberta-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "ZY2mheQJhSYu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We perform class inheritance and customize the classifier head"
      ],
      "metadata": {
        "id": "_jnmONhbi-RB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(AutoModelForSequenceClassification):\n",
        "    def __init__(self, config):\n",
        "        super(CustomModel, self).__init__(config)\n",
        "        self.classifier = nn.Sequential(\n",
        "            nn.Linear(config.hidden_size, 526),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(526, 258),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(0.1),\n",
        "            nn.Linear(258, config.num_labels)\n",
        "        )\n",
        "\n",
        "    def forward(self, **inputs):\n",
        "        outputs = self.roberta(**inputs)\n",
        "        sequence_output = outputs[0]\n",
        "        logits = self.classifier(sequence_output[:, 0, :].squeeze(1))\n",
        "        return logits\n"
      ],
      "metadata": {
        "id": "bMNK7Kk0i17y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the training hyperparameters and initialize the trainer"
      ],
      "metadata": {
        "id": "CEZq9VZSjQMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cp_model = CustomModel.from_pretrained(model_path, num_labels=6)\n",
        "cp_model.to(device)\n",
        "\n",
        "batch_size = 64\n",
        "logging_steps = len(small_train_ds) // batch_size\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"results\",\n",
        "    num_train_epochs=8,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    learning_rate=2e-5,\n",
        "    load_best_model_at_end=True,\n",
        "    metric_for_best_model=\"f1\",\n",
        "    weight_decay=0.01,\n",
        "    eval_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    run_name=\"roberta_head_classification\",\n",
        "    disable_tqdm=False,\n",
        "    logging_steps=logging_steps,\n",
        ")"
      ],
      "metadata": {
        "id": "liQsEKt_jOlm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Initialize the trainer"
      ],
      "metadata": {
        "id": "tHOXrAn6jqpV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=cp_model,\n",
        "    args=training_args,\n",
        "    train_dataset=small_train_ds,\n",
        "    eval_dataset=small_val_ds,\n",
        "    compute_metrics=compute_metrics,\n",
        ")"
      ],
      "metadata": {
        "id": "-ZXvHgvpjspX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the model"
      ],
      "metadata": {
        "id": "wI7I-F2Lj1fd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "gvhUe_-Pj3aY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluate the model on the evaluation dataset"
      ],
      "metadata": {
        "id": "MiJp0J1Tj4GI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()"
      ],
      "metadata": {
        "id": "Fjr73XE2kDIe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use it for predictions in the test dataset"
      ],
      "metadata": {
        "id": "4xcXknGGkKXv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(small_test_ds)"
      ],
      "metadata": {
        "id": "Mxr5g-DSkPGf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.metrics"
      ],
      "metadata": {
        "id": "Bm3A9EU6kRko"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "predictions.predictions contains the raw model outputs, which are typically probability distributions or logits for each class"
      ],
      "metadata": {
        "id": "VXLGrpctkj8x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.predictions"
      ],
      "metadata": {
        "id": "FntGox8JkhnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The predicted label is the one with the maximum value along each row :"
      ],
      "metadata": {
        "id": "sN_9zT5OkxJd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(predictions.predictions, axis=1)"
      ],
      "metadata": {
        "id": "MyvCKxkelAXF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(small_test_ds['label'].numpy(),y_preds ))"
      ],
      "metadata": {
        "id": "8mPKmZSslCdd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the model"
      ],
      "metadata": {
        "id": "nT_Jm0V9lLL8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./model/custom_head')\n",
        "tokenizer.save_pretrained('./model/custom_head')"
      ],
      "metadata": {
        "id": "knbKRZLalTC2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r './model/custom_head' /content/drive/MyDrive/NLP_data/model/custom_head"
      ],
      "metadata": {
        "id": "a0jdebkYlbdY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune RoBERTa on our dataset\n",
        "\n",
        "The other approach is to  simply fine tune the RobertaForSequenceClassification on our dataset, by following the previous steps but not customizing the head."
      ],
      "metadata": {
        "id": "0qZqyMu0gQ5I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RobertaForSequenceClassification.from_pretrained(\"FacebookAI/roberta-base\", num_labels = 6).to(device)"
      ],
      "metadata": {
        "id": "suwW2hYwl4l8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "logging_steps = len(small_train_ds) // batch_size\n",
        "\n",
        "training_args = TrainingArguments(output_dir=\"results\",\n",
        "                                  num_train_epochs=10,\n",
        "                                  learning_rate=5e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  load_best_model_at_end=True,\n",
        "                                  warmup_steps=500,\n",
        "                                  metric_for_best_model=\"f1\",\n",
        "                                  weight_decay=0.03,\n",
        "                                  eval_strategy=\"epoch\",\n",
        "                                  save_strategy=\"epoch\",\n",
        "                                  run_name = \"roberta_classification\",\n",
        "                                  disable_tqdm=False)"
      ],
      "metadata": {
        "id": "uGMmjmq5l9H5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=small_train_ds,\n",
        "                  eval_dataset=small_val_ds)"
      ],
      "metadata": {
        "id": "zdDk0ZA6l_-Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "TzOUMP2lmUPm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()\n",
        "results"
      ],
      "metadata": {
        "id": "7hu17xNzmXC1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = trainer.predict(small_test_ds)"
      ],
      "metadata": {
        "id": "bIB3l3l1muWY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "predictions.metrics"
      ],
      "metadata": {
        "id": "rx2b6AXTmxXV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(predictions.predictions, axis=1)"
      ],
      "metadata": {
        "id": "-tMQhVNUm1T9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(small_test_ds['label'].numpy(),y_preds ))"
      ],
      "metadata": {
        "id": "irAR5vuSm30r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save model"
      ],
      "metadata": {
        "id": "UcYM7FLFm8t0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('./model')\n",
        "tokenizer.save_pretrained('./model')"
      ],
      "metadata": {
        "id": "NMkasmpAm_JU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r './model' /content/drive/MyDrive/NLP_data/model/"
      ],
      "metadata": {
        "id": "QFK8Os4XnDSM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load model\n",
        "If needed you can load the model from the drive location you have it saved"
      ],
      "metadata": {
        "id": "RlfbBvounGqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!cp -r /content/drive/MyDrive/NLP_data/model/ './model'"
      ],
      "metadata": {
        "id": "agDGvE1ZnRc2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model_path = \"./model\""
      ],
      "metadata": {
        "id": "zgsaZTTKnYVW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(model_path)"
      ],
      "metadata": {
        "id": "7HMaFTLvnb_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Push model to Hugging Face\n",
        "\n",
        "Once it is uploaded, add the label mapping at the config.json\n",
        "   ```\n",
        "   \"id2label\": {\n",
        "     \"0\": \"Sadness\",\n",
        "     \"1\": \"Joy\",\n",
        "    \"2\": \"Love\",\n",
        "     \"3\": \"Anger\",\n",
        "     \"4\": \"Fear\",\n",
        "     \"5\": \"Surprise\"\n",
        "   }\n",
        "    ```"
      ],
      "metadata": {
        "id": "l6-NRiwpfr3o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "id": "31JMmlddoEk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global credential.helper store"
      ],
      "metadata": {
        "id": "nAVXEp4KoHii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install git-lfs"
      ],
      "metadata": {
        "id": "Fb1Nl08MoJr_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use your git credentials\n",
        "!git config --global user.email \"\"\n",
        "!git config --global user.name \"\"\n",
        "!git config --global user.password \"\""
      ],
      "metadata": {
        "id": "iJx9yWhIoNRy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.push_to_hub(\"roberta-base-emotion\")"
      ],
      "metadata": {
        "id": "3Ol357YGoSD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.push_to_hub(\"roberta-base-emotion\")"
      ],
      "metadata": {
        "id": "zF9Ut5W9oU5e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pipeline use demo"
      ],
      "metadata": {
        "id": "9gy2wmGhgvh3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = pipeline(model=\"Dimi-G/roberta-base-emotion\")"
      ],
      "metadata": {
        "id": "kvNa5iiXgiFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions=classifier('i feel very happy and excited since i learned so many things', top_k=None)"
      ],
      "metadata": {
        "id": "xMSGAS0lobdy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions"
      ],
      "metadata": {
        "id": "LCyLBvmeokgG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}